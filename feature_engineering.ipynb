{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import pandas as pd \r\n",
    "#create a series of datetime with a frequency of 10 hours\r\n",
    "s = pd.date_range('2020-01-06', '2020-01-10', freq ='10H').to_series()\r\n",
    "#create some features based on datetime\r\n",
    "#gen a dictionary of features from a given series...ab\r\n",
    "features = {\r\n",
    "    \"dayofweek\":s.dt.dayofweek.values,\r\n",
    "    \"dayofyear\": s.dt.dayofyear.values, \r\n",
    "    \"hour\": s.dt.hour.values,\r\n",
    "    \"is_leap_year\": s.dt.is_leap_year.values,\r\n",
    "    \"quarter\": s.dt.quarter.values,\r\n",
    "    \"weekofyear\": s.dt.weekofyear.values\r\n",
    "}\r\n",
    "print(s)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020-01-06 00:00:00   2020-01-06 00:00:00\n",
      "2020-01-06 10:00:00   2020-01-06 10:00:00\n",
      "2020-01-06 20:00:00   2020-01-06 20:00:00\n",
      "2020-01-07 06:00:00   2020-01-07 06:00:00\n",
      "2020-01-07 16:00:00   2020-01-07 16:00:00\n",
      "2020-01-08 02:00:00   2020-01-08 02:00:00\n",
      "2020-01-08 12:00:00   2020-01-08 12:00:00\n",
      "2020-01-08 22:00:00   2020-01-08 22:00:00\n",
      "2020-01-09 08:00:00   2020-01-09 08:00:00\n",
      "2020-01-09 18:00:00   2020-01-09 18:00:00\n",
      "Freq: 10H, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def generate_features(df):\r\n",
    "    #create a bunch of features using date columns\r\n",
    "    df.loc[:, 'year'] = df['date'].dt.year\r\n",
    "    df.loc[:, 'weekofyear'] = df['date'].dt.weekofyear\r\n",
    "    df.loc[:, 'month'] = df['date'].dt.month\r\n",
    "    df.loc[:, 'dayofweek'] = df['date'].dt.dayofweek\r\n",
    "    df.loc[:, 'weekend'] = (df['date'].dt.weekday >=5).astype(int)\r\n",
    "    # create an aggregate dictionary\r\n",
    "    aggs = {}\r\n",
    "    # for aggregation by month, we calculate the\r\n",
    "    # number of unique month values and also the mean\r\n",
    "    aggs['month'] = ['nunique', 'mean']\r\n",
    "    aggs['weekofyear'] = ['nunique', 'mean']\r\n",
    "    # we aggregate by num1 and calculate sum, max, min\r\n",
    "    # and mean values of this column\r\n",
    "    aggs['num1'] = ['sum','max','min','mean']\r\n",
    "    # for customer_id, we calculate the total count\r\n",
    "    aggs['customer_id'] = ['size']\r\n",
    "    # again for customer_id, we calculate the total unique\r\n",
    "    aggs['customer_id'] = ['nunique']\r\n",
    "    # we group by customer_id and calculate the aggregates\r\n",
    "    agg_df = df.groupby('customer_id').agg(aggs)\r\n",
    "    agg_df = agg_df.reset_index()\r\n",
    "    return agg_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#example : create a bunch of statistical features, x is a list of values \r\n",
    "import numpy as np \r\n",
    "feature_dict = {}\r\n",
    "\r\n",
    "x=[1,2,3,4,5,6]\r\n",
    "#calculate mean \r\n",
    "feature_dict['mean'] = np.mean(x)\r\n",
    "#calculate max\r\n",
    "feature_dict['max'] = np.max(x)\r\n",
    "#calculate min \r\n",
    "feature_dict['min'] = np.min(x)\r\n",
    "#calculate std deviation\r\n",
    "feature_dict['std'] = np.std(x)\r\n",
    "#calculate variance\r\n",
    "feature_dict['var'] = np.var(x)\r\n",
    "#calculate peek-to-peek \r\n",
    "feature_dict['ptp'] = np.ptp(x)\r\n",
    "# #calculate percentile\r\n",
    "feature_dict['percentile_10'] = np.percentile(x, 10)\r\n",
    "feature_dict['percentile_60'] = np.percentile(x, 60)\r\n",
    "feature_dict['percentile_90'] = np.percentile(x, 90)\r\n",
    "#calculate quantile\r\n",
    "feature_dict['quantile_5'] = np.percentile(x, 5)\r\n",
    "feature_dict['quantile_95'] = np.percentile(x, 95)\r\n",
    "feature_dict['quantile_99'] = np.percentile(x, 99)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# example: gen a random dataframe with 2 columns and 100 rows\r\n",
    "\r\n",
    "import numpy as np \r\n",
    "df = pd.DataFrame(np.random.rand(100,2), \r\n",
    "    columns=[f\"f_{i}\" for i in range(1,3)])\r\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         f_1       f_2\n",
       "0   0.351790  0.619431\n",
       "1   0.370736  0.003406\n",
       "2   0.873181  0.828888\n",
       "3   0.050860  0.099718\n",
       "4   0.595553  0.674058\n",
       "..       ...       ...\n",
       "95  0.242844  0.922599\n",
       "96  0.289261  0.637347\n",
       "97  0.928571  0.619644\n",
       "98  0.730984  0.266064\n",
       "99  0.437142  0.596048\n",
       "\n",
       "[100 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.351790</td>\n",
       "      <td>0.619431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.370736</td>\n",
       "      <td>0.003406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.873181</td>\n",
       "      <td>0.828888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.050860</td>\n",
       "      <td>0.099718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.595553</td>\n",
       "      <td>0.674058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.242844</td>\n",
       "      <td>0.922599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.289261</td>\n",
       "      <td>0.637347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.619644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.730984</td>\n",
       "      <td>0.266064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.437142</td>\n",
       "      <td>0.596048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# create two-degree polynominal features using PolynominalFeatures, from scikit-learn \r\n",
    "from sklearn import preprocessing\r\n",
    "\r\n",
    "pf = preprocessing.PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\r\n",
    "#fit to the features\r\n",
    "pf.fit(df)\r\n",
    "#create polynominal features \r\n",
    "poly_feats = pf.transform(df)\r\n",
    "\r\n",
    "#create a df with all the features\r\n",
    "num_feats = poly_feats.shape[1]\r\n",
    "print('num_feats = ',num_feats)\r\n",
    "df_transformed = pd.DataFrame(\r\n",
    "    poly_feats,\r\n",
    "    columns=[f\"f_{i}\" for i in range(1, num_feats + 1)]\r\n",
    "    )\r\n",
    "df_transformed\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_feats =  5\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         f_1       f_2       f_3       f_4       f_5\n",
       "0   0.351790  0.619431  0.123757  0.217910  0.383694\n",
       "1   0.370736  0.003406  0.137445  0.001263  0.000012\n",
       "2   0.873181  0.828888  0.762445  0.723769  0.687055\n",
       "3   0.050860  0.099718  0.002587  0.005072  0.009944\n",
       "4   0.595553  0.674058  0.354683  0.401437  0.454354\n",
       "..       ...       ...       ...       ...       ...\n",
       "95  0.242844  0.922599  0.058973  0.224048  0.851189\n",
       "96  0.289261  0.637347  0.083672  0.184360  0.406211\n",
       "97  0.928571  0.619644  0.862245  0.575384  0.383959\n",
       "98  0.730984  0.266064  0.534338  0.194489  0.070790\n",
       "99  0.437142  0.596048  0.191093  0.260558  0.355274\n",
       "\n",
       "[100 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.351790</td>\n",
       "      <td>0.619431</td>\n",
       "      <td>0.123757</td>\n",
       "      <td>0.217910</td>\n",
       "      <td>0.383694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.370736</td>\n",
       "      <td>0.003406</td>\n",
       "      <td>0.137445</td>\n",
       "      <td>0.001263</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.873181</td>\n",
       "      <td>0.828888</td>\n",
       "      <td>0.762445</td>\n",
       "      <td>0.723769</td>\n",
       "      <td>0.687055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.050860</td>\n",
       "      <td>0.099718</td>\n",
       "      <td>0.002587</td>\n",
       "      <td>0.005072</td>\n",
       "      <td>0.009944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.595553</td>\n",
       "      <td>0.674058</td>\n",
       "      <td>0.354683</td>\n",
       "      <td>0.401437</td>\n",
       "      <td>0.454354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.242844</td>\n",
       "      <td>0.922599</td>\n",
       "      <td>0.058973</td>\n",
       "      <td>0.224048</td>\n",
       "      <td>0.851189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.289261</td>\n",
       "      <td>0.637347</td>\n",
       "      <td>0.083672</td>\n",
       "      <td>0.184360</td>\n",
       "      <td>0.406211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.619644</td>\n",
       "      <td>0.862245</td>\n",
       "      <td>0.575384</td>\n",
       "      <td>0.383959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.730984</td>\n",
       "      <td>0.266064</td>\n",
       "      <td>0.534338</td>\n",
       "      <td>0.194489</td>\n",
       "      <td>0.070790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.437142</td>\n",
       "      <td>0.596048</td>\n",
       "      <td>0.191093</td>\n",
       "      <td>0.260558</td>\n",
       "      <td>0.355274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Handle mising/NaN values**\r\n",
    "- Categorical features: treat is as a new category\r\n",
    "- numerical data: choose a value that does not appear in the specific feature and fill using that\r\n",
    "    ví dụ: \r\n",
    "    - giá trị 0 ko có ở trong feature >> có thể thay các giá trị nan bằng 0. đây là cách đơn giản nhưng ko hiệu quả\r\n",
    "    - thay vì fill 0 thì dùng mean hoặc median của tất cả các giá trị...\r\n",
    "    - sử dụng k-nearest neighbour \r\n",
    "    - huấn luyện 1 mô hình regression , để dự đoán giá trị khuyết thiếu trong 1 cột dựa trên các cột khác...\r\n",
    "    "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "#KNNImputer\r\n",
    "\r\n",
    "import numpy as np \r\n",
    "from sklearn import impute\r\n",
    "\r\n",
    "#create a random numpy arr with 10 samples and 6 features and values ranging from 1 to 15\r\n",
    "X = np.random.randint(1,15, (10,6))\r\n",
    "#convert the arr to float \r\n",
    "X= X.astype(float)\r\n",
    "# randomly assign 10 elements to NaN (missing)\r\n",
    "X.ravel()[np.random.choice(X.size, 10, replace=False)] = np.nan\r\n",
    "#use 3 nearest neighbours to fill na values \r\n",
    "knn_imputer = impute.KNNImputer(n_neighbors=2)\r\n",
    "knn_imputer.fit_transform(X)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 6. ,  8. ,  9. ,  4. ,  8. ,  6. ],\n",
       "       [ 3. ,  9. ,  5. ,  2. ,  9.5,  1. ],\n",
       "       [ 2. , 12. ,  7. ,  3.5, 13. ,  6. ],\n",
       "       [ 9. ,  8. ,  7. ,  2. ,  8. ,  2. ],\n",
       "       [ 5. , 10. , 13. ,  1. ,  3. ,  2. ],\n",
       "       [ 3. ,  9. ,  7. ,  6. ,  6. ,  3.5],\n",
       "       [14. ,  3. , 11. ,  2. ,  8. ,  3. ],\n",
       "       [11. ,  4. , 14. ,  2. , 11. , 11. ],\n",
       "       [ 2.5, 13. ,  4. ,  5. ,  8. , 12. ],\n",
       "       [ 2.5,  7. ,  3. , 12. , 10.5, 10. ]])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Note** \r\n",
    "- Look at the data and see what fits and create features accordingly \r\n",
    "- Scale or nomalize your features if using linear models (logistic regression, SVM, ...). \r\n",
    "  Tree-based model will work fine without any normalization of features"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "9f54772c6dbcef3e2bbb3b58a12d0ea93cc39e8d73ca8d1792b5e194a83990cc"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}